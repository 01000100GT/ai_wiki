# 1. deepspeed + pdsh方案

  TODO：
  - 未测试代码和数据是否需要自行同步

## 1.1 简介

- 优点：在1太机器启动，即可自动启动其余机器，避免以前在每天机器都得启一遍脚本的麻烦
- 缺点：会导致tqdm无法正常显示
  
pdsh是deepspeed里面可选的一种分布式训练工具。适合你有几台裸机，
它的优点是只需要在一台机上运行脚本就可以，
pdsh会自动帮你把命令和环境变量推送到其他节点上，然后汇总所有节点的日志到主节点。

要用pdsh前，你得自己给所有的机器配一样的环境，配ssh，
把所有机器之间都通过ssh的秘钥文件设置成不需要密码登录，然后安装pdsh，准备工作就结束了。

## 1.2 免密登录配置

1. 安装

    ```bash
       sudo apt-get install pdsh
    ```

2. 生成sshkey：

    ```bash
       ssh-keygen -t rsa
    ```
    
    执行后一直回车就行生成sshkey的存储路径：~/.ssh/id_rsa

3. 服务器互相拷贝实现免密登录
    
    不加-p则使用默认端口
    
    注意：如下命令需要在每台服务器执行，本机也需要对自己ssh免密设置
    
    ```bash
        ssh-copy-id -p 22 root@124.23.134.178
        ssh-copy-id -p 22 root@124.32.143.156
    ```

4. 实验是否可以互相登录成功

   不加-p则使用默认端口
   
   ```bash
       ssh -p '22' 'root@124.23.134.178'
   ```

5. 系统hostfile配置
  
   在每台机器上分别执行
   
   ```bash
    vim ~/.ssh/config
   ```
   
   在文件中配置每台机器信息（注：该文件中不能加注释，否则会引起错误）
   ```
    Host huaweiyun1
        HostName 1.2.3.4     
        User root
        Port 33               
    
    Host huaweiyun2
        HostName 4.5.6.7    
        User root
        Port 33               
    ```

## 1.3 Deepspeed配置

1. deepspeed使用的hostfile配置
   
   ```
      huaweiyun1 slots=8
      huaweiyun2 slots=8
   ``` 
   
   通过pdsh，仅在一台服务器启动脚本即可，其它服务器机会自动启动。
   
   pdsh会影响tqdm在多机上的显示，但比较省事，只需在一台服务器启动即可。


2. 模型存放位置

    模型存放在启动任务的那台服务器上


# 2.  accelerate + pdsh

/root/.cache/huggingface/accelerate/default_config.yaml

   
# 3. 问题和注意事项

1. 训练慢

    最后就是如果多机多卡训练很慢的话（GPU占用100%但是功率很低），
    很可能是你的NCCL走了socket导致的，这时候可以传入环境变量，将NCCL_NET改为IB就行了：
    
    ```
    export NCCL_NET=IB
    ```


# 参考

[1] 