# 1. 资源
学习率调整方法类的详细参数及类方法定义，请参考 pytorch 官方库文档-torch.optim。

# 2. 详解
在实际应用中，以 pytorch 框架为例，pyTorch 提供了六种学习率调整方法，
可分为三大类，分别是:

- 有序调整：按照一定规律有序进行调整，这一类是最常用的，分别是等间隔下降(Step)， 
  按需设定下降间隔(MultiStep)，指数下降(Exponential)和 CosineAnnealing。
  这四种方法的调整时机都是人为可控的，也是训练时常用到的。
- 自适应调整: 如依据训练状况伺机调整 ReduceLROnPlateau 方法。
  该法通过监测某一指标的变化情况，当该指标不再怎么变化的时候，就是调整学习率的时机，因而属于自适应的调整。
- 自定义调整: 自定义调整 Lambda。Lambda 方法提供的调整策略十分灵活，
  我们可以为不同的层设定不同的学习率调整方法，这在 fine-tune 中十分有用，
  我们不仅可为不同的层设定不同的学习率，还可以为其设定不同的学习率调整策略，简直不能更棒了!

常见的学习率调整方法有:
- lr_scheduler.StepLR: 等间隔调整学习率。调整倍数为 gamma 倍，调整间隔为 step_size。
- lr_scheduler.MultiStepLR: 按设定的间隔调整学习率。适合后期使用，通过观察 loss 曲线，手动定制学习率调整时机。
- lr_scheduler.ExponentialLR: 按指数衰减调整学习率，调整公式:
- lr_scheduler.CosineAnnealingLR: 以余弦函数为周期，并在每个周期最大值时重新设置学习率。
- lr_scheduler.ReduceLROnPlateau: 当某指标不再变化(下降或升高)，调整学习率（非常实用的策略）。
- lr_scheduler.LambdaLR: 为不同参数组设定不同学习率调整策略。


学习率衰减常用参数有哪些

|  参数名称 | 参数说明 | 
|----|----|
| learning_rate | 初始学习率 |
| global_step | 用于衰减计算的全局步数，非负，用于逐步计算衰减指数 |
| decay_steps | 衰减步数，必须是正值，决定衰减周期 |
| decay_rate | 衰减率 |
| end_learning_rate | 最低的最终学习率 |
| cycle | 学习率下降后是否重新上升 |
| alpha | 最小学习率 |
| num_periods |衰减余弦部分的周期数 |
| initial_variance | 噪声的初始方差 |
| variance_decay | 衰减噪声的方差 |

```
注意，PyTorch 1.1.0 之后版本，学习率调整策略的设定必须放在优化器设定的后面! 
构建一个优化器，首先需要为它指定一个待优化的参数的可迭代对象，然后设置特定于优化器的选项，
比如学习率、权重衰减策略等。
```

```
在 PyTorch 1.1.0 之前，学习率调度器应该在优化器更新之前被调用；
1.1.0 以打破 BC 的方式改变了这种行为。如果在优化器更新（调用 optimizer.step()）
之前使用学习率调度器（调用 scheduler.step()），后果是将跳过学习率调度的第一个值。
```

使用指数级衰减的学习率调整策略的模板代码如下。
 
```python
import torchvision.models as models
import torch.optim as optim
model = models.resnet50(pretrained=False)

optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # 构建优化器，lr 是初始学习率
scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9) # 设定学习率调整策略

for epoch in range(20):
    for input, target in dataset:
        optimizer.zero_grad()
        output = model(input)
        loss = loss_fn(output, target)
        loss.backward()
        optimizer.step()
    scheduler.step()
    print_lr(is_verbose=true) # pytorch 新版本可用，1.4及以下版本不可用
```

# 参考

[1] 深度学习炼丹-超参数设定和模型训练, https://mp.weixin.qq.com/s/upps5iZYHzRCZbEZ0wyvBg
