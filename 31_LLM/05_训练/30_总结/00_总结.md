# 1. 总结
汇总对比各类模型技术报告，总结数据使用和训练优化手段。

# 2. 数据清洗

基本流程都是：规则 + 去重 + 模型质量打分

# 3. 预训练策略
数据量：
- 预训练阶段，以前的模型基本使用2T左右token，最新的模型都到8-15T token左右
- 混合质量数据，有助性能提升

长度优化：
- 长度优化：先用4k长度的数据训练，然后加入少量32k长度的数据继续训练 （因为越长，attention计算类就越大）
- 使用插值类方法扩展
- 长数据并行化
- 使用rope等位置编码方式

为了加速，主要的改进是：
- 4D并行训练：数据、模型、长度和张量并行
- 改进attention计算

# 4. SFT
大部分模型都仅使用10k-100k的数据，但是有的模型使用了100w级别的数据（如internlm）

# 5. RLHF
- 大部分模型使用的PPO，并使用了在线RLHF
- 大部分使用100w级别的数据，有的仅使用了20w级别的数据（如internlm）
