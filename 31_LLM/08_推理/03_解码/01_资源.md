1. LLMSpeculativeSampling

   - https://github.com/feifeibear/LLMSpeculativeSampling
   - 265 stars
   - 复现Fast inference from large lauguage models via speculative decoding
   - 解码加速：小模型预测，大模型修正，起到加速作用

2. PainlessInferenceAcceleration
    
   - https://github.com/alipay/PainlessInferenceAcceleration
   - 161 Stars
   - Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy
   - 解码加速方案：用在RAG上的lookahead解码