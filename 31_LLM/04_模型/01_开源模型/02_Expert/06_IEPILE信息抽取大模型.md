# 1. 介绍

IEPILE:大规模基于Schema的信息抽取语料库
   - 论文题目：IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus
   - 本文作者：桂鸿浩（浙江大学、蚂蚁集团）、袁琳（蚂蚁集团）、叶宏彬（浙江大学）、张宁豫（浙江大学、浙江大学-蚂蚁集团联合实验室）、孙梦姝（蚂蚁集团、浙江大学-蚂蚁集团联合实验室）、梁磊（蚂蚁集团、浙江大学-蚂蚁集团联合实验室）、陈华钧（浙江大学、浙江大学-蚂蚁集团联合实验室）
   - 发表会议：ACL2024
   - 论文链接：https://arxiv.org/abs/2402.14710
   - 代码链接：https://github.com/zjunlp/IEPile
   - Modelscope下载路径：https://modelscope.cn/datasets/ZJUNLP/IEPile
   - 模型下载：https://modelscope.cn/models/ZJUNLP/OneKE
   - 一个全面的双语（英语和汉语）IE指令语料库——IEPile，它包含大约0.32B个字符
   - 实验表明，IEPile提高了LLMs的信息提取性能，特别是在零样本泛化方面有显著提升
   - 本语料库主要涉及中英双语的材料，并集中于命名实体识别（NER）、关系抽取（RE）和事件抽取（EE）三大类信息抽取任务。我们总共收集了15个英文NER数据集，3个中文NER数据集，8个英文RE数据集，2个中文RE数据集，以及3个英文EE数据集和2个中文EE数据集。为保证数据质量和格式的统一，我们对数据进行了规范化处理，包括格式统一、实例去重、筛除低质量数据。
   - 三条启发式规则以排除质量较低且无意义的数据：1）非字母字符占比超过80%；2）文本长度小于5个字符且不含任何标签；3）停用词如'the'、'to'、'of'等占比超过80%。我们认为以上所述的清洗措施将对模型的训练产生积极影响，并提高其性能

# 2. 方法

为了广泛覆盖各个领域，并尽可能满足实际的信息提取需求，我们从多个数据源中收集了信息抽取任务所需的数据集。本语料库主要涉及中英双语的材料，并集中于命名实体识别（NER）、关系抽取（RE）和事件抽取（EE）三大类信息抽取任务。我们总共收集了15个英文NER数据集，3个中文NER数据集，8个英文RE数据集，2个中文RE数据集，以及3个英文EE数据集和2个中文EE数据集。为保证数据质量和格式的统一，我们对数据进行了规范化处理，包括格式统一、实例去重、筛除低质量数据。

我们构建了三条启发式规则以排除质量较低且无意义的数据：1）非字母字符占比超过80%；2）文本长度小于5个字符且不含任何标签；3）停用词如'the'、'to'、'of'等占比超过80%。我们认为以上所述的清洗措施将对模型的训练产生积极影响，并提高其性能。

我们专注于基于指令的信息抽取，因此指令中的schema的构造至关重要，因为它反映着具体抽取需求，是动态可变的。然而，现有研究在构造指令时往往采取一种较为粗放的schema处理策略，即利用标签集内全部schema进行指令构建。这种方法潜在地存在三个重要的问题：

1. 缺乏纯正的反例样本。例如，在像conll2004这种数据集中，每个样本至少关联一个标签，从而在输出中至少含有一个有效值。这可能使模型在预测时过分依赖至少输出一个值的假定。
2. 训练和评估阶段schema询问的数量不一致，即使这些schema在内容上相似，可能损害模型的泛化能力。若训练过程中每次询问的schema数量大约是20个，而评估时询问的是10个或30个schema，即使这些schema在内容上与训练阶段相似，模型性能仍可能受到影响。
3. 指令中的schema之间的对比性不足。语义近似的schema，如“裁员”、“离职”与“解雇”，它们的语义模糊性可能造成模型混淆。这类易混淆的模式应当在指令集中更为频繁地出现。

因此，我们提出如下解决方案：1、轮询式的指令生成；2、构造难负样本字典。

![](.06_IEPILE信息抽取大模型_images/构造流程.png)




# 参考

[1] ACL2024 | IEPILE:大规模基于Schema的信息抽取语料库，https://mp.weixin.qq.com/s/atgUn_nYd4Gy-SaLHZbPIw
