# 1. 模型列表

无商用限制模型：

1. CPM-Bee 10B

   模型信息卡地址：https://www.datalearner.com/ai-models/pretrained-models/CPM-Bee
   
   模型有如下特点：

   - 训练质量较高：CPM-Bee 10B在超过1万亿tokens的数据集上训练，训练数据中包含200GB高质量中文数据集，
     且模型参数达到100亿，在国产开源领域目前应该是最优秀的一类（ChatGLM-6B和Baichuan 7B开源模型参数规模只有60-70亿，
     复旦大学的MOSS开源模型参数规模虽然有160亿，但是训练数据只有7000多tokens）。

   - 社区生态良好：开源大模型一个很重要的方面是社区的支持和生态的丰富程度。不同的人对LLM的使用需求差异很大，
     因此对模型微调和改造是开源LLM是否吸引人的重要因素。CPM-Bee 10B在GitHub上开源并提供了模型微调、
     模型联网等内容和工具，并且背后有一个OpenBMB社区提供官方支持，对于使用者来说非常友好。

   - 模型易用性高：CPM-Bee已经整合到HuggingFace的著名开源库transformers中，
     可以直接按照transformer官方使用方法调用，与主流生态兼容性高。而在使用方面，官方还提供了微调脚本，
     只需要准备好数据即可直接运行微调脚本获得在我们自己数据集上微调后的大模型，十分简单方便。

   - 使用成本较低：CPM-Bee 10B模型的推理显存占用仅需20GB即可，在单张消费级显卡（RTX 3090 24GB）上即可运行，
     它也开源了5B、2B和1B版本，最低仅需6GB显存即可使用，因此使用成本很低。

   - 免费商用授权：CPM-Bee 10B最重要的一点是商用授权免费，只需要发送邮件申请纸质授权即可
    （官方透露电子邮件申请，纸质授权包邮到家哦~）。
   
   
   官方提供了一个邮箱地址（cpm@modelbest.cn）供大家申请，只需要填写发送邮件获取表格即可申请。
   申请成功之后官方应该会免费邮寄一个纸质授权书。从CPM-Bee 10B的生态建设和社区支持看，该模型未来发展十分值得期待。

   大家也可以从DataLearner信息卡中获得更多CPM-Bee 10B相关的信息，包括GitHub开源地址、
   官方网站等：https://www.datalearner.com/ai-models/pretrained-models/CPM-Bee

# 参考
[1] 清华大学100亿参数规模的免费商用授权大模型：CPM-Bee 10B, https://mp.weixin.qq.com/s/hqE1UIhnAI23uQ0Z5R9opw