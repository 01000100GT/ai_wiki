# 1. 安装

参见：[llama-factory](https://github.com/hiyouga/LLaMA-Factory.git)

可以直接拉去docker使用最简单，python环境装在了系统下面，没有装conda

<summary>For Ascend NPU users</summary>

To install LLaMA Factory on Ascend NPU devices, please specify extra dependencies: `pip install -e ".[torch-npu,metrics]"`. Additionally, you need to install the **[Ascend CANN Toolkit and Kernels](https://www.hiascend.com/developer/download/community/result?module=cann)**. Please follow the [installation tutorial](https://www.hiascend.com/document/detail/en/CANNCommunityEdition/600alphaX/softwareinstall/instg/atlasdeploy_03_0031.html) or use the following commands:

```bash
# replace the url according to your CANN version and devices
# install CANN Toolkit
wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C17SPC701/Ascend-cann-toolkit_8.0.RC1.alpha001_linux-"$(uname -i)".run
bash Ascend-cann-toolkit_8.0.RC1.alpha001_linux-"$(uname -i)".run --install

# install CANN Kernels
wget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C17SPC701/Ascend-cann-kernels-910b_8.0.RC1.alpha001_linux.run
bash Ascend-cann-kernels-910b_8.0.RC1.alpha001_linux.run --install

# set env variables
source /usr/local/Ascend/ascend-toolkit/set_env.sh
```

| Requirement  | Minimum | Recommend   |
| ------------ | ------- | ----------- |
| CANN         | 8.0.RC1 | 8.0.RC1     |
| torch        | 2.1.0   | 2.1.0       |
| torch-npu    | 2.1.0   | 2.1.0.post3 |
| deepspeed    | 0.13.2  | 0.13.2      |

Remember to use `ASCEND_RT_VISIBLE_DEVICES` instead of `CUDA_VISIBLE_DEVICES` to specify the device to use.

If you cannot infer model on NPU devices, try setting `do_sample: false` in the configurations.

Download the pre-built Docker images: [32GB](http://mirrors.cn-central-221.ovaijisuan.com/detail/130.html) | [64GB](http://mirrors.cn-central-221.ovaijisuan.com/detail/131.html)

# 2. docker使用

## 2.1 docker 常见命令

使用llama-factory的昇腾镜像

```bash
# 查看image
docker image ls

# 查看在运行的容器
docker ps

# 查看所有容器
docker ps -a

# 停止容器
docker stop <container_id>

# 删除容器
docker rm <container_id>
```

## 2.2 docker使用

参见：http://mirrors.cn-central-221.ovaijisuan.com/detail/130.html

python环境装在了系统下面，没有装conda

版本信息
- Python版本：3.10.13
- CANN版本：8.0
- 操作系统版本：Ubuntu18.08
- 昇腾驱动固件版本：23.0.0以上

镜像拉取命令
```
docker pull swr.cn-east-317.qdrgznjszx.com/donggang/llama-factory-ascend910:cann8-py310-torch2.2.0-ubuntu18.04
```

镜像启动参考

创建一个docker_run.sh文件，将下面代码copy到文件中，保存并执行即可启动镜像。（由于网站显示问题请在下面docker run命令的每一行后面加一个反斜杠）

官方启动命令如下：

```bash
#!/bin/bash

docker_images=swr.cn-east-317.qdrgznjszx.com/donggang/llama-factory-ascend910:cann8-py310-torch2.2.0-ubuntu18.04
model_dir=/root/xxx

docker run -it -u root --ipc=host --net=host    
        --device=/dev/davinci0    
        --device=/dev/davinci1    
        --device=/dev/davinci2    
        --device=/dev/davinci3     
        --device=/dev/davinci4     
        --device=/dev/davinci5     
        --device=/dev/davinci6    
        --device=/dev/davinci7    
        --device=/dev/davinci_manager    
        --device=/dev/devmm_svm    
        --device=/dev/hisi_hdc    
        -v /usr/local/Ascend/driver:/usr/local/Ascend/driver    
        -v /usr/local/Ascend/add-ons/:/usr/local/Ascend/add-ons/    
        -v /usr/local/sbin/npu-smi:/usr/local/sbin/npu-smi    
        -v ${model_dir}:${model_dir}    
        -v /var/log/npu:/usr/slog ${docker_images}    
        /bin/bash
```

上面使用的--ipc=host --net=host 是映射全局所有端口，如果一个人使用这台机器还好，好多人使用，容易端口问题，因此，可使用如下脚本限制端口

```bash
#!/bin/bash

# 镜像名称
docker_images=swr.cn-east-317.qdrgznjszx.com/donggang/llama-factory-ascend910:cann8-py310-torch2.2.0-ubuntu18.04  
model_dir=/root/mdl_zoo  # 待挂载的模型路径目录
prg_dir=/root/rag_mdl/prj/mdl_server  # 待挂载的代码路径目录

# 只挂载0-3号卡，name指定容器名称，容器内端口内部60-70映射到外部的8060-8070
docker run -itd --name lf -p 8060-8070:60-70 -u root \
        --device=/dev/davinci0 \
        --device=/dev/davinci1 \
        --device=/dev/davinci2 \
        --device=/dev/davinci3 \
        --device=/dev/davinci_manager \
        --device=/dev/devmm_svm \
        --device=/dev/hisi_hdc \
        -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \
        -v /usr/local/Ascend/add-ons/:/usr/local/Ascend/add-ons/ \
        -v /usr/local/sbin/npu-smi:/usr/local/sbin/npu-smi \
        -v ${prg_dir}:${prg_dir} \
        -v ${model_dir}:${model_dir} \
        -v /var/log/npu:/usr/slog ${docker_images} \
        /bin/bash
```

进入容器命令

```bash
#!/bin/bash

# lf未容器名称
docker exec -ti lf /bin/bash
```

## 2.3 启动LLM

创建qwen2_7B_Instruct.yaml

```yaml
model_name_or_path: /root/mdl_zoo/qwen/Qwen2-7B-Instruct
template: qwen
do_sample: false # 不设false可能报错
```

启动openai服务

```bash
#!/bin/bash

# 如果报找不到这个库，则引入
export LD_PRELOAD=$LD_PRELOAD:/usr/local/python3.10.13/lib/python3.10/site-packages/sklearn/utils/../../scikit_learn.libs/libgomp-d22c30c5.so.1.0.0
# 使用1和2号卡，端口号62
ASCEND_RT_VISIBLE_DEVICES=1,2 API_PORT=62 llamafactory-cli api qwen2_7B_Instruct.yaml
```

# 3. 测试

910A输入10，输出500
- 单卡17 token/s
- 双卡7token/s （通讯速度慢）

# 4. FAQ 

docker login报错 x509

报错打印

```bash
Error response from daemon: Get "https://swr.cn-east-317.qdrgznjszx.com/v2/": tls: failed to verify certificate: x509: certificate signed by unknown authority
```

原因证书问题，证书验证错误

配置dns vim /etc/docker/daemon.json 写入下面内容

```bash
{ "insecure-registries": ["https://swr.cn-east-317.qdrgznjszx.com"], "registry-mirrors": ["https://docker.mirrors.ustc.edu.cn"] }
```

然后重启docker即可 systemctl restart docker.service

镜像地址

在其他AICC使用本镜像时，

1. 在本地arm宿主机通过docker pull 拉取上面镜像到本地（即执行docker pull remote_image_address）
2. 用docker tag 将局点信息和组织名替换成对应版本（即执行 docker tag local_image_address remote_image_address），
3. 用docker push 将修改后的镜像名称推送到局点的swr服务中（即执行docker push remote_image_address）

```bash
swr.cn-east-317.qdrgznjszx.com/donggang/llama-factory-ascend910:llamafactory0.7.2.dev0-cann8-py310-torch2.2.0-ubuntu18.04
```