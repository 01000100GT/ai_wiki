# 1. 数据
数据驱动是当下的核心思想。

## 1.1 数据集划分及性能验证
1. 数据集划分
   通常按如下进行划分：
    - 训练集：用于学习参数的数据子集（不要和整个训练过程用到的更大的数据集搞混）
    - 验证集：用于挑选超参数的数据子集，估计训练中或训练后的泛化误差，用来更新超参数
    - 测试集：评估模型的性能，通常尽可能使用更多的不同场景的测试集，以评估模型性能

    在没有额外的测试集的情况下，把一个大集子按照7:2:1的比例进行划分。

2. 交叉验证
   由于深度学习都采用超大的数据量规模进行训练，且训练时间较长，较少使用该方法对模型进行评估，该方法
   常见与机器学习中。

## 1.2 数据配比
在大型项目中，往往遇到一个模型需要在多个场景（比如，NLP的会议、学校、旅游不同场景）达到性能要求，
尽可能按照1：1配比，同时可能需要调节配比数量。   

## 1.3 数据筛选
数据并不是越多越好，主要源于如下几个原因：
- 数据虽多，但是相似度都太高（比如同一个说话人说的同一句话，说了好多遍），容易导致过拟合
- 现实中，往往数据标注质量没有那么高，导致错误的数据加入，反而影响性能

因此，最常用的数据筛选方法：
- 先训练一个模型，通过阈值过滤数据，把模型认为不好的数据丢掉，往复迭代，可以加速模型收敛
- 用不同场景的数据训练多个模型，多个模型联合打分筛选
- 训练一个更大的模型，性能往往更好，进行筛选（不过，注意过拟合问题）
- 通过主动学习的方法，筛选出有价值的数据，之后人工进行标注
- 其它更高级的方法，暂时不在此处讨论

## 1.4 数据训练顺序
顺序策略：
- 乱序有助于更好的学习
- 如语音或文本，按照长度排序，一是避免无效padding补0，增加训练时间，其次，避免模型学到长短差异的信息

送入到模型的训练数据一定要充分打乱（shuffle），这样在使用自适应学习率算法的时候，
可以避免某些特征集中出现，而导致的有时学习过度、有时学习不足，
使得下降方向出现偏差的问题。同时，信息论（information theor）中也曾提到: 
“从不相似的事件中学习总是比从相似事件中学习更具信息量”。

另外，为了方便做实验对比，建议设定好随机数种子! 并且，模型每轮（epoch）
训练进行前将训练数据集随机打乱（shuffle），确保模型不同轮数相同批次“看到”的数据是不同的。

## 1.5 数据增广
数据增强（图像增强）的策略必须结合具体任务来设计！数据增强的手段有多种，
常见的如下（除了前三种以外，其他的要慎重考虑）:

- 水平 / 竖直翻转
- 90°，180°，270° 旋转
- 翻转 + 旋转(旋转和翻转其实是保证了数据特征的旋转不变性能被模型学习到，卷积层面的方法可以参考论文 ACNet)
- 亮度，饱和度，对比度的随机变化
- 随机裁剪（Random Crop）
- 随机缩放（Random Resize）
- 加模糊（Blurring）
- 加高斯噪声（Gaussian Noise）
- 随机掩蔽图片中的一部分
- 随机扣去图中的一小块，用另一小块进行替换

## 1.6 数据质量
在显存满足的情况下，一般输入图片尺寸越大，模型精度越高！
