# 1. 中文
## 1.1 短句相似检索

1. BAAI-MTP
   - 下载路径：https://data.baai.ac.cn/details/BAAI-MTP
   - 对现有可用的中英文网络文本数据进行收集、整理，我们最终获得了总计3亿条的文本对数据(1.3TB)，
     其中英文文本对2亿条(634GB)，中文文本对1亿条(666GB)。
   
2. infgrad/retrieval_data_llm
    - 194k (Query, Positive Document, Hard negative Document)
    - https://huggingface.co/datasets/infgrad/retrieval_data_llm
    - 对应模型：https://huggingface.co/infgrad/stella-large-zh-v3-1792d

3. nli_zh 
   - 较老的数据集
   - Huggingface下载网址：https://huggingface.co/datasets/shibing624/nli_zh
   - Github网址 （README中的几个原始网址已无法找到）：https://github.com/IceFlameWorm/NLP_Datasets
   - 包含ATEC语义相似度学习赛数据集、CCKS 2018 微众银行智能客服问句匹配大赛数据集、
     哈工大BQ_corpus数据集、哈工大LCQMC数据集

## 1.2 长文档检索

1. MLDR
   BAAI-MLDR
   - 13国多语种文件检索数据，BGE-M3模型开源数据
   - 基于Wikipeida, Wudao and mC4构建，随机抽取片段，GPT3.5生成问题，问题和片段
     构成pair对
   - 下载路径：https://huggingface.co/datasets/Shitao/MLDR
   - prompt: “You are a curious AI assistant, please generate one 
     specific and valuable question based on the following text. 
     The generated question should revolve around the core 
     content of this text, and avoid using pronouns (e.g., ”this”). 
     Note that you should generate only one question, without 
     including additional content:”.
   
# 2. 英文

1. BAAI-MTP
   - 下载路径：https://data.baai.ac.cn/details/BAAI-MTP
   - 对现有可用的中英文网络文本数据进行收集、整理，我们最终获得了总计3亿条的文本对数据(1.3TB)，
     其中英文文本对2亿条(634GB)，中文文本对1亿条(666GB)。

2. nomic
   - Github (361 stars): https://github.com/nomic-ai/contrastors
   - 代码、数据、模型全量开放，以英文为主
   - 数据下载方法：
     - 1.注册账户：atlas.nomic.ai
     - 2.安装python客户端 (注意：nomic login会给出网址，点击后，获取api token，然后输入nomic login --token=token)
       - ```bash
         pip install nomic
         nomic login # follow prompts to login
         python -c "from nomic import atlas; print(atlas._get_datastream_credentials(name='contrastors'))"
         ```
     - 获取AWS的登录密钥（数据存储在亚马逊AWS服务上）：通过上述步骤可获取AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
     - 安装amazon aws (数据存放在该s3桶上):
       - AWS官方使用文档：https://docs.aws.amazon.com/zh_cn/cli/latest/userguide/getting-started-quickstart.html
       - windows安装方法直接安装msi包，linux安装方法如下：
         - ```bash
           curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
           unzip awscliv2.zip
           sudo ./aws/install
           ```
     - 验证是否安装成功（linux和windows都可以在命令行下操作）：
       - ```bash
         aws --version
         ```
     - 配置aws
       - aws configure：（命令行输出如下提示，可以配置，之后就可以了）
       - ```bash 
          AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE
          AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
          Default region name [None]: us-west-2
          Default output format [None]: json
         ```
     - 查看数据 (第一个为原始数据4.1TB，第二个为筛选后的为325GB)
       - ```bash
         aws s3 ls --endpoint-url=https://9fa58365a1a3d032127970d0bd9a1290.r2.cloudflarestorage.com/ s3://contrastive
         aws s3 ls --endpoint-url=https://9fa58365a1a3d032127970d0bd9a1290.r2.cloudflarestorage.com/ s3://contrastive-index-filtered
         ```
     - 查看文件大小
       - ```bash
         aws s3 ls --summarize --human-readable --recursive s3://bucket/folder/*
         ```
     - 下载数据
       - 单个数据文件夹 （如果不加--recursive，会报错）
         - ```bash
           aws s3 cp --endpoint-url=https://9fa58365a1a3d032127970d0bd9a1290.r2.cloudflarestorage.com/ s3://contrastive-index-filtered/contrastive-index-filtered-000000000000.jsonl . --recursive
           ```
       - 整个s3桶下载
         - ```bash
           aws s3 sync --endpoint-url=https://9fa58365a1a3d032127970d0bd9a1290.r2.cloudflarestorage.com/ s3://contrastive . 
           ```
     
# 3. 多语种

1. bge-m3-data
   - BGE-M3模型开源数据，172k，短数据，多语种
   - https://huggingface.co/datasets/Shitao/bge-m3-data

2. wikipedia-2023-11-embed-multilingual-v3
   - 300多种语言的Wikipedia嵌入表示的数据集，包含embedding值
   - https://huggingface.co/datasets/Cohere/wikipedia-2023-11-embed-multilingual-v3

# 参考

[1] 新手AWS S3下载数据集必学入门教程，https://blog.csdn.net/qq_41397220/article/details/133308580
