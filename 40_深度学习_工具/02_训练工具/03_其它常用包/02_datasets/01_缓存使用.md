# 1. 简介

参考：https://hugging-face.cn/docs/datasets/cache

下载或对token操作时，默认会将数据缓存在 ~/.cache/huggingface/hub下，导致空间占用很大

实测网址中给的禁用或者清理缓存方法均不生效，因此，采取更换缓存目录的方法

# 2. 解决方案
## 2.1 更改缓存目录

```bash
export HF_DATASETS_CACHE="/path/to/another/directory/datasets"
```

加载数据集时，还可以选择更改数据缓存的位置。将 cache_dir 参数更改为您想要使用的路径。

```python
from datasets import load_dataset
dataset = load_dataset('username/dataset', cache_dir="/path/to/another/directory/datasets")
```

## 2.2 缓存文件
使用 Dataset.cleanup_cache_files() 清理目录中的 Arrow 缓存文件。

```python
# Returns the number of removed cache files
dataset.cleanup_cache_files()
```

# 3. 从缓存直接加载之前处理过的数据

```python
updated_dataset = small_dataset.map(add_prefix, load_from_cache_file=True)
```

# 4. 提升性能
禁用缓存并将数据集复制到内存中可以加快数据集操作速度。有两种方法可以将数据集复制到内存中。

将 datasets.config.IN_MEMORY_MAX_SIZE 设置为一个非零值（以字节为单位），该值适合您的 RAM 内存。

将环境变量 HF_DATASETS_IN_MEMORY_MAX_SIZE 设置为一个非零值。请注意，第一种方法优先级更高。
