Github (285 stars): https://github.com/dvlab-research/Step-DPO

支持qwen训练