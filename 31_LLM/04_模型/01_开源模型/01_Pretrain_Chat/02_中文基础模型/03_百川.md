# 1. baichuan-13b

Baichuan-13B 有如下几个特点：

- 更大尺寸、更多数据：Baichuan-13B 在 Baichuan-7B 的基础上进一步扩大参数量到 130 亿，
  并且在高质量的语料上训练了 1.4 万亿 tokens，超过LLaMA-13B 40%，是当前开源 13B 
  尺寸下训练数据量最多的模型。支持中英双语，使用 ALiBi 位置编码，上下文窗口长度为 4096。
- 同时开源预训练和对齐模型：预训练模型是适用开发者的『 基座 』，而广大普通用户对有对话功能的
  对齐模型具有更强的需求。因此本次开源同时发布了对齐模型（Baichuan-13B-Chat），
  具有很强的对话能力，开箱即用，几行代码即可简单的部署。
- 更高效的推理：为了支持更广大用户的使用，本次同时开源了 int8 和 int4 的量化版本，
  相对非量化版本在几乎没有效果损失的情况下大大降低了部署的机器资源门槛，可以部署在如 Nvidia 3090 这样的消费级显卡上。
- 开源免费可商用：Baichuan-13B 不仅对学术研究完全开放，开发者也仅需邮件申请并获得官方商用许可后，即可以免费商用。

