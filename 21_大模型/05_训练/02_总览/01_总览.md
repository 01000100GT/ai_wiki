1. Collect demonstration data, and train a supervised policy (supervised fine-tune, SFT).
2. Collect comparison data, and train a reward model (RM).
3. Optimize a policy against the reward model using PPO.

Steps 2 and 3 can be iterated continuously.

![](.01_总览_images/InstructGPT训练流程.png)


# 参考

[1] InstructGPT, https://daviddmc.github.io/blog/2022/InstructGPT/