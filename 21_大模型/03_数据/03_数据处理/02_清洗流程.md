# 1. 百川

## 1.1 预训练数据

- 整合各类信息源，确保文化、科学、技术等方面广泛的知识覆盖；
- 建立了一套系统的数据质量体系，包括低质、优质、类别等
- 设计了一个多粒度的大规模聚类系统。通过使用先进的聚类算法和方法，识别和整合相似或相关的数据，为去重、采样提供支撑
- 一种细粒度的自动化匹配算法，自动配比各类任务，例如课程学习。从而实现个性化的模型学习，使预训练数据能够更精确地匹配用户需求

## 1.2 搜索增强

- 动态响应策略：依赖 Prompt，将指令任务细化为 16 个独立类别，覆盖各种用户指令的场景。
- 智能化搜索词生成：通过对问答样本进行精细化的人工标注，捕捉和理解用户多元化的志林需求。
- 高质量搜索结果筛选：百川构建了一个搜索结果相关性模型，对从搜索内容和知识库中获取的信息进行相关性频分，
                  从而筛选出高质量的搜索引用内容，减少在知识抽取阶段引入的无关、低质量的信息。
- 回答结果的搜索增强：RLHF，让 Baichuan 大模型参照搜索结果，针对用户请求生成高价值且具有实时性的回答。


# 2. Llama2-Chinese

- https://github.com/FlagAlpha/Llama2-Chinese
- 5.9k Stars

## 2.1 预训练数据

- 采用大规模的中文数据进行持续预训练，包含百科、书籍、博客、新闻、公告、小说、金融数据、法律数据、
  医疗数据、代码数据、专业论文数据、中文自然语言处理竞赛数据集等
- 数据来源：https://github.com/FlagAlpha/Llama2-Chinese#-%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90
- 对庞大的数据进行了过滤、打分、去重，筛选出超过1T token的高质量中文数据，持续不断加入训练迭代中


# 参考

[1] LLM（一）| 百川智能baichuan7B、13B、53B以及baichuan2总结, https://zhuanlan.zhihu.com/p/656857636