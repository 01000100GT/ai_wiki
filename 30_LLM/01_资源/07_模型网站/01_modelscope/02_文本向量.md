1. CoROM文本向量-中文-通用领域-base
   - https://modelscope.cn/models/damo/nlp_corom_sentence-embedding_chinese-base/summary
   - 原理：在Dual Encoder框架中, Query和Document文本通过预训练语言模型编码后, 
          通常采用预训练语言模型[CLS]位置的向量作为最终的文本向量表示。基于标注数据的标签, 
          通过计算query-document之间的cosine距离度量两者之间的相关性。
     
     ![](.02_文本向量_images/Dual_encoder.png)

2. MaSTS文本相似度-中文-搜索-CLUE语义匹配-large
   - https://modelscope.cn/models/damo/nlp_masts_sentence-similarity_clue_chinese-large/summary
   - 原理：输入形如（文本A，文本B）的文本对数据，模型会给出该文本对相关性的标签（“0”，"1"，"2"）以及相应的概率。
          相关性的含义：0，相关程度差；1，有一定相关性；2，非常相关。数字越大相关性越高。