1. 降低批量大小（Batch Size）： 如果您在训练模型，尝试减少批量大小。这将减少每个训练迭代所需的内存。我是先把batch_size设置为1，观察显存用了多少。
2. 优化模型： 查看模型是否有优化空间，例如减少层的数量或减小层的尺寸。但最好不要缩减模型大小。
3. 清理缓存： 尝试使用torch.cuda.empty_cache()来清理未被使用的缓存。虽然这个方法不能解决根本问题，但有时可以帮助管理GPU内存的使用。
4. 使用16位精度训练（Mixed Precision Training）： 使用混合精度训练可以减少内存使用并加速训练。
5. 设置max_split_size_mb： 错误信息提到了“设置max_split_size_mb以避免碎片化”。可以尝试设置一个较小的max_split_size_mb值。这样做可以减少因为内存碎片化而导致的内存溢出。可以通过设置环境变量 PYTORCH_CUDA_ALLOC_CONF 来指定 max_split_size_mb 的值。在运行Python脚本之前设置这个环境变量。
6. 将"pin_memory": True改为False

# 参考

[1] CUDA out of memory 怎么解决？，https://www.zhihu.com/question/447012868/answers/updated
[2] 大概率（5重方法）解决RuntimeError: CUDA out of memory. Tried to allocate ... MiB, https://blog.csdn.net/wtyuong/article/details/129751928