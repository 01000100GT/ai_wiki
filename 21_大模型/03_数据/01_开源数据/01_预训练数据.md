1. Wikipedia: 中文Wikipedia的数据
   - https://github.com/goldsmith/Wikipedia
   - 2.7k stars
   - 提供python API

2. 悟道（智源）
   - 5T, 开源200G
   - 采用 20 多种规则从 100TB 原始网页数据中清洗得出最终数据集，注重隐私数据信息的去除，源头上避免 GPT-3 
     存在的隐私泄露风险；包含教育、科技等 50+个行业数据标签，可以支持多领域预训练模型的训练
   - https://data.baai.ac.cn/details/WuDaoCorporaText
   - https://github.com/yuanzhoulvpi2017/zero_nlp/wiki/%E6%95%B0%E6%8D%AE%E5%85%B1%E4%BA%AB%E2%80%94%E2%80%94%E6%82%9F%E9%81%93200G%E6%95%B0%E6%8D%AE%E5%88%86%E4%BA%AB

3. MNBVC
   - https://github.com/esbatmop/MNBVC
   - 2k stars
   - MNBVC(Massive Never-ending BT Vast Chinese corpus)超大规模中文语料集。
     对标chatGPT训练的40T数据。MNBVC数据集不但包括主流文化，
     也包括各个小众文化甚至火星文的数据。MNBVC数据集包括新闻、作文、小说、
     书籍、杂志、论文、台词、帖子、wiki、古诗、歌词、商品介绍、笑话、糗事、
     聊天记录等一切形式的纯文本中文数据。
   - 包含数据清洗工具