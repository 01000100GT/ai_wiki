- Yi-34B模型int4量化之后，相比float16损失<1%，可以跑在RTX4090上（24G显存）
- 模型结构不需要太多变化，LLAMA2标准结构已经足够训出很好的效果
- 3.1T的预训练数据远比scaling law建议的1T大，但是效果更好，并且模型还没饱和，继续增大数据量还能提升
- 微调数据质量很重要，由算法人员直接标注，只要<10k的数据量就足够了
- 4k长度的基础预训练模型已经具备长文本能力，只需用长文本数据继续预训练，更新百步就有很好效果
- 总之，数据要精心设计，数据质量要高，数据量要大

![](.01_01Yi_images/量化版本性能对比.png)

结构上，基于标准LLAMA2模型，做了一些变化

- 注意力机制：LLAMA2只在70B用了GQA，Yi全系列都用了GQA，具体参数如下表
- 位置编码：RoPE，参考RoPE ABF（《Effective long-context scaling of foundation models》），base扩大到10M，用于支持长上下文。
- 激活函数：使用SwiGLU，参考《GLU Variants Improve Transformer》
- 并且把activation size从4h降为8/3h，这里的说法是补偿了GQA带来的参数下降

# 参考

[1] Yi技术报告-划重点看细节， https://mp.weixin.qq.com/s/T4oAvLkgCarN3dXErDsPKA
