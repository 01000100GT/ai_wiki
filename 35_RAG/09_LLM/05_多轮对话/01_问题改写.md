# 1. 问题

例如，RAG里面的多轮对话和chat的多轮对话不太一样，RAG需要用query去检索。举个例子：

q1: 张三这个人怎么样？

a1: 张三………

q2: 和李四比呢？

如果拿q2去检索，那拿到的片段全是李四的信息，没有张三的信息，回答会文不对题。

ag里面，有时候用户可能问一些问题，必须基于上下文才能看懂的，这些问题一般要怎么改造，然后给到向量数据库去进行文档搜索啊，例如就问了一句，还有吗，这样给过去效果应该很差。要把上下文总结到最终的问题里面，但试了好些prompt，效果也一般般，不是说全部问题都能做到能把这个问题描述清楚。

# 2. 解决方法

其中一个很重要的模块就是qury understand，这个做的就是对query的理解和改写。

这类问题一个比较显而易见的解决方案是：基于上述对话，对当前问题进行改写，使得语义更明确，完整，处理方式就是改写/复述。，也就是通过LLM大模型把历史对话和当前问题改写成一个独立问题，比如这里会改写成，张三和李四相比怎么样？然后再拿这个新的q去做检索。

但这存在的两个很大的问题，如果只是讲上文所有信息都加载至prompt进行请求，则容易导致长文本过长，并且无效字符串过多。

但是改写问题也要把历史对话传过去，同样也费token，技巧来了，传多少，怎么传。是不是要过滤掉一些无用的上下文？答案是的，可以采用比如限定历史轮次，比如压缩上下文等方案，有一些是每隔一段，做一个总结，特别是咨询场景。

另一个是，因为LLM大模型有幻觉，这个问题改写可能会被改错，这个时候就需要引入一个新的问题，就是受控改写，比如引入知识图谱？

# 参考

[1] 20240313大模型进展早报：兼论大模型FAQ生成及RAG多轮问答. https://mp.weixin.qq.com/s/6bIIT1yT46gjAa1l6nSMYQ