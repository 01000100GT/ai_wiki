- Github: https://github.com/unslothai/unsloth
- further accelerate QLoRA / LoRA (2x faster, 60% less memory) and even full-finetuning (1.1x faster)
- supports only Llama (Yi, TinyLlama as well) and Mistral architectures.

# 参考 
[1] sft_trainer, https://huggingface.co/docs/trl/sft_trainer