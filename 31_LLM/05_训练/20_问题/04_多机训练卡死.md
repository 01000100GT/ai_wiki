1. 不同步原因

    这个问题一般是因为不同的node之间gather的时候数据不一致导致的，具体来说有这几种可能：
    loss_dict不一致，比如你定义了多个loss，node1跑的是loss1，node2跑的是loss2，
    如果你的loss_dict没有为这些loss值设置默认值，就会一直waiting
    metric_dict不一致，比如node1你记录了l2loss，node2你记录了IOU，也会有这种情况
    一般检查这两个就可以解决，通常直接把log_dict里的sync关掉，即不使用跨节点的metrics计算会减少这种问题出现的概率


# 参考
[1] 分布式多机多卡训练卡住，超时后报错, https://github.com/IDEA-CCNL/Fengshenbang-LM/issues/123