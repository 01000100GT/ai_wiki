# 1. 主要方法

1. HyDE: 
   - LLM在虚构文档生成后，再使用无监督检索器进行 Embedding；然后将生成的向量在本地知识库中进行相似性检索，寻找最终结果。
   - LangChain和Llama-index中都有实现
   - 结论：效果不一定好，且开销大结论：效果不一定好，且开销大

# 2. 问题

1. 基于检索的主要方法：

   - 将用户问题和本地知识进行 Embedding，通过向量相似度(Vector Similarity)实现召回；
   - 通过LLM对用户问题进行意图识别；并对原始答案加工整合。

2. 现有问题：

   (1) 知识点聚合处理场景下，Embedding-Search 召回精度较低 的问题。典型应用范式是：

    - 一个仓库有 N 条记录，每个记录有 M 个属性；
    - 用户希望对 x 条记录的y 个属性进行查询、对比、统计等处理。

    这种场景在游戏攻略问答中很常见，以体育游戏 NBA2K Online2 为例：
    
    - 多知识点——简单查询   
      Q: 皮蓬、英格利什和布兰德的身高、体重各是多少？
    - 多知识点——筛选过滤   
      Q: 皮蓬、英格利什和布兰德谁的第一位置是 PF？
    - 多知识点——求最值   
      Q: 皮蓬、英格利什和布兰德谁的金徽章数最多？

   (2) 单个知识点方便建索引，不同知识点排列组合建索引，开销巨大。

    ![](.01_关系抽取匹配_images/单个和组合索引.png)

   (3) 原始问题直接 Embedding ，和单条知识点的向量相似度比较低。
   
     降低 相似度评分下限(vector similarity score threshold)，同时提高召回结果数量上限(top k)。并产生不好的副效应：

     - 召回结果，有效信息密度大幅降低；score threshold 过高或 top k 过低，会导致某些有效知识点无法命中；
       反之，很多无效知识点或噪声会被引入。且由于总 token 数量的限制，导致本地知识点被截断，遗漏相似度较低但有效的知识点。
     - 召回结果的膨胀，增加了和 LLM 交互的 token 开销；增加了 LLM 处理的时间复杂度。再直白点：既慢又花钱。
     - 更糟糕的是，给 LLM 的分析处理带来额外噪声，影响最终答案的正确性。
   
    对召回结果整合后的反馈，耗时高，且结果不正确。

# 3. 解决方案

通过问题理解，准确识别用户意图解决

1. HyDE
   
   结论：效果不一定好，且开销大
 
   原理：

   - 根据意图，制定计划，拆分为若干步骤；在每个步骤选择合适的工具进行处理；
     根据每个步骤返回的结果，动态决定下一步的方案。比如：要分析球员的位置，应按下述步骤拆解：
     - 了解到底有哪些球员
     - 查询这些球员的位置各是什么
     - 对位置信息进行处理：基于召回结果，对用户问题进行推理。
   - 规划生成的单个步骤，做好抽象和封装，明确输入和输出以及执行逻辑。

   有了 Agents 和 Chains的标准抽象，下面再来看看摸清用户意图的几种方法，这样才能开发合适的工具：

   - Precise Zero-Shot Dense Retrieval without Relevance Labels 一文面向 zero-shot场景下的稠密检索 ，
     使用基础模型在训练过程中已经掌握的相关语料，面向用户问题，生成虚构的文档。该文档的作用，不是输出最终结果，
     而是通过 LLM 对问题的理解能力，生成与之相关的内容。这相当于自动化生成相关性标签，避免外部输入。虚构文档生成后，
     再使用无监督检索器进行 Embedding；然后将生成的向量在本地知识库中进行相似性检索，寻找最终结果。上述过程在原论文中也提供了示意图：
   
     ![](.01_关系抽取匹配_images/HyDE.png)
   
     HyDE 要求与用户问题相关的知识，已经存在于 LLM 基础模型中。但专业领域知识，可能本来就是未联网、未公开的；LLM 生成的虚构文档，
     可能包含很多噪音，所以效果不一定很明显；另外生成文档的额外交互，进一步增加了时间开销。目前，LangChain 提供了
     HyDE Chain，LlamaIndex 也提供了类似的能力；大家有兴趣可以尝试，面对中文可能需要自定义 Prompt Template。

2. 实体+槽位填充

   - 在为用户提供服务的预设场景下，细分用户各种意图的类别，定制对应的语义槽，每个槽位可以视为在语义层面体现意图的基本单位。
   - 通过深度学习、统计学习，甚至 LLM ，理解用户问题提取语义槽中需要的内容。
   - ```shell
        "球员打法" : {
        "球员名称" : ____,
        "年代" : ____,
        "比赛模式": ____,
      }
   ```
 
![](.01_关系抽取匹配_images/基于关键词检索流程图.png)

# 参考

[1] LLM+Embedding构建问答系统的局限性及优化方案, https://zhuanlan.zhihu.com/p/641132245