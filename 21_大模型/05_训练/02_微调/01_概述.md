# 简介

微调对话任务的时候，微调会导致模型的理解能力别削弱（无法理解相似语义的输入），
即当输入数据prompt的分布与训练数据分布不一致时，模型不会按照训练集的response进行输出，
而是使用模型原有的能力进行输出，模型输出结果出现不可控的情况。这个时候需要对输入的数据进行数据增强，
数据的方法很多，但个人认为对于样本比较少的对话，最有效的方式应该是人工进行标注，
即人工写出输入数据prompt的各种可能的语义相似的样本来(根据对数据增强方式的理解，如：释义、采样和加噪)


# 1. Prompt Tuning

当前大多数大模型都是通过让用户做prompt工程来提高模型的输出准确性，
方法的优点是不改变模型参数即可获得正确的结果，缺点则是需要对输入进行反复尝试和调优。

# 2. Decoder Tuning

Decoder Tuning则是对输出结果进行调整获得更好的结果，尽管这种方法相比prompt工程需要
多一点的时间，但是效果却更好。官方宣称该方法可以仅仅使用API的情况下，不访问和修改模型
参数即可大幅提高下游任务的性能。测试结果CPM-Bee 10B的任务效果从基础模型的61.9分提高
到了85.6分，这也是十分值得期待的特性。

# 3. P-Tuning V2

- Github: https://github.com/THUDM/P-tuning-v2
- 论文：P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally
       Across Scales and Tasks，https://arxiv.org/abs/2110.07602

Prompt tuning（Lester等人，2021），或Ptuning（Liu等人，2021b），引入了可训练的连续提示，
作为主干模型的参数被冻结时对NLU的自然语言提示的替代。例如，V指的是语言模型M的单词表，e作为模型M的嵌入函数。

要把一篇电影评论x="了不起的电影！"分类为正面或负面，自然会想到在评论中附加一个提示 "它是[MASK]"，
并生成mask token被预测为 "好 "或 "坏 "的条件概率作为分类。在这种情况下，提示token{"它"、"是"、"[MASK]"}
都属于模型的单词表V，而输入嵌入序列将为

![](.01_概述_images/p-tuning公式1.png)

然而，由于模型M本质上是连续的，从优化的角度来看，用离散的自然提示语永远不可能达到最优。
相反，P-tuning建议用可训练的连续嵌入[h0，...，hi]代替提示token，并将输入序列变成

![](.01_概述_images/p-tuning公式2.png)

因此，可以进行不同的优化（参考图2（a））。在骨干预训练模型的参数被冻结的严格约束下，
在简单的NLU任务（Lester等人，2021；Kim等人，2021）和知识探测（Liu等人，2021b）中，
提示优化已被证明具有与100亿参数模型的微调相当的性能。

![](.01_概述_images/ptuning_v2.png)

图：从Lester等人（2021）&P-tuning到P-tuning v2。 橙色token（包括h0，hi）是指我们添加的提示嵌入；
蓝色token是由冻结的预训练语言模型存储或计算的嵌入。与Lester等人（2021）相比，
P-tuning v2将可训练的连续提示独立添加到每个transformer层的输入中（正如前缀优化（Li and Liang, 2021）所做的那样）。
此外，P-tuning v2删除了带有LM头的verbalizers，并返回到带有普通线性头的传统类别标签，以允许其任务的普遍性。


# 参考
[1] 清华大学100亿参数规模的免费商用授权大模型：CPM-Bee 10B, https://mp.weixin.qq.com/s/hqE1UIhnAI23uQ0Z5R9opw
[2] P-Tuning v2: 与微调性能相等的提示性优化，https://zhuanlan.zhihu.com/p/423902902
[3] ChatGLM多轮对话微调-多轮对话训练数据的自动生成（标注）, https://blog.csdn.net/wxl781227/article/details/131005577