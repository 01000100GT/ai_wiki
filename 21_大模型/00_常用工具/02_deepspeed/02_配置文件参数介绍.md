# 1. 简介

级别介绍：
- ZeRO-0：禁用所有类型的分片，仅使用 DeepSpeed 作为 DDP (Distributed Data Parallel)
- ZeRO-1：分割Optimizer States，减少了4倍的内存，通信容量与数据并行性相同
- ZeRO-2：分割Optimizer States与Gradients，8x内存减少，通信容量与数据并行性相同
- ZeRO-3：分割Optimizer States、Gradients与Parameters，内存减少与数据并行度和复杂度成线性关系。
- ZeRO-Infinity是ZeRO-3的拓展。允许通过使用 NVMe 固态硬盘扩展 GPU 和 CPU 内存来训练大型模型。ZeRO-Infinity 需要启用 ZeRO-3。

在deepspeed中通过zero_optimization.stage=0/1/2/3 设置，
卸载通过zero_optimization.offload_optimizer.device设置

混合精度：Choose between ['no', 'fp8', 'fp16', 'bf16']


# 2. 配置文件说明

```json
{
  "train_batch_size": 24,
  "train_micro_batch_size_per_gpu": 1,
  "gradient_accumulation_steps": 1,
  "steps_per_print": 1,
  "zero_optimization": {
    "stage": 3,
    "offload_param": {
      "device": "cpu",
       "pin_memory": true
    },
    "offload_optimizer": {
      "device": "cpu",
      "pin_memory": true
    },
    "allgather_partitions": true,
    "allgather_bucket_size": 1e7,
    "overlap_comm": true,
    "reduce_scatter": true,
    "reduce_bucket_size": 1e7,
    "contiguous_gradients" : true,
    "stage3_prefetch_bucket_size": "auto",
    "stage3_param_persistence_threshold": "auto",
    "stage3_max_live_parameters": 1e9,
    "stage3_max_reuse_distance": 1e9,
    "stage3_gather_16bit_weights_on_model_save": true
  },
  "bf16": {
    "enabled": false
  },
  "fp16": {
    "enabled": true,
    "loss_scale": 0,
    "loss_scale_window": 100
  },
  "gradient_clipping": 0.5,
  "prescale_gradients": false,
  "wall_clock_breakdown": false
}

```

参数解释

fp16.loss_scale=0：自动放缩
fp16.enabled=auto: 根据传参进行自适应混合精度模式
fp16.initial_scale_power=16：初始放大率是2的16次方
fp16.min_loss_scale=1：最小放大率为1，如果为1时仍然梯度溢出，程序则会报错
gradient_clipping=1：梯度剪裁

