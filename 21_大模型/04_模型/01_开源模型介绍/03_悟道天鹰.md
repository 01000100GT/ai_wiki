# 1. 简介

Aquila2 模型全系开源地址：
- https://github.com/FlagAI-Open/Aquila2
- https://model.baai.ac.cn/
- https://huggingface.co/BAAI

- 全面升级Aquila2模型系列：Aquila2-34B/7B基础模型，AquilaChat2-34B/7B对话模型，AquilaSQL“文本-SQL语言”模型
- 广受欢迎的语义向量模型BGE新版本升级，4大检索诉求全覆盖
- FlagScale 高效并行训练框架，训练吞吐量、GPU 利用率业界领先
- FlagAttention 高性能Attention算子集，创新支撑长文本训练、Triton语言

长文本处理：

AquilaChat2-34B-16K以Aquila2-34B为基座，经过位置编码内插法处理，
并在20W条优质长文本对话数据集上做了SFT，将模型的有效上下文窗口长度扩展至16K

# 2. 评测

评测说明：
对于生成式对话模型，智源团队认为需要严格按照“模型在问题输入下自由生成的答案”进行评判，这种方式贴近用户真实使用场景，
因此参考斯坦福大学HELM[1]工作进行评测，该评测对于模型的上下文学习和指令跟随能力要求更为严格。实际评测过程中，
部分对话模型回答不符合指令要求，可能会出现“0”分的情况。例如：根据指令要求，正确答案为“A”，
如果模型生成为“B”或“答案是 A ”，都会被判为“0”分。同时，业内也有其他评测方式，
比如让对话模型先拼接“问题+答案”，模型计算各个拼接文本的概率后，验证概率最高的答案与正确答案是否一致，
评测过程中对话模型不会生成任何内容而是计算选项概率。这种评测方式与真实对话场景偏差较大，因此在生成式对话模型评测中没有采纳。
[1] https://crfm.stanford.edu/helm/latest


# 参考

[1] 最强开源中英双语大模型：悟道·天鹰340亿携全家桶登场, https://zhuanlan.zhihu.com/p/660950105